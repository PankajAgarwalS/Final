# -*- coding: utf-8 -*-
"""HPC1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/192pYW5_yUZCYKlYbRqVac34G-P3MUhYt
"""

!apt update -y
!apt install gcc -y

# Commented out IPython magic to ensure Python compatibility.
# # Step 1: Write the code to a .c file
# %%writefile parallel_bfs_dfs.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <omp.h>
# 
# #define MAX_NODES 100
# 
# int graph[MAX_NODES][MAX_NODES];
# int visited[MAX_NODES];
# int queue[MAX_NODES];
# int front = 0, rear = -1;
# 
# void enqueue(int node) {
#     queue[++rear] = node;
# }
# 
# int dequeue() {
#     return queue[front++];
# }
# 
# int isQueueEmpty() {
#     return front > rear;
# }
# 
# void parallelBFS(int start, int n) {
#     enqueue(start);
#     visited[start] = 1;
# 
#     while (!isQueueEmpty()) {
#         int currentSize = rear - front + 1;
# 
#         #pragma omp parallel for shared(queue, graph, visited, currentSize)
#         for (int i = 0; i < currentSize; i++) {
#             int node;
# 
#             #pragma omp critical
#             {
#                 node = dequeue();
#                 printf("Visited %d by thread %d\n", node, omp_get_thread_num());
#             }
# 
#             for (int j = 0; j < n; j++) {
#                 if (graph[node][j] && !visited[j]) {
#                     #pragma omp critical
#                     {
#                         if (!visited[j]) {
#                             visited[j] = 1;
#                             enqueue(j);
#                         }
#                     }
#                 }
#             }
#         }
#     }
# }
# 
# void dfsTask(int node, int n) {
#     int shouldProceed = 0;
# 
#     #pragma omp critical
#     {
#         if (!visited[node]) {
#             visited[node] = 1;
#             printf("Visited %d by thread %d\n", node, omp_get_thread_num());
#             shouldProceed = 1;
#         }
#     }
# 
#     if (!shouldProceed) return;
# 
#     for (int i = 0; i < n; i++) {
#         if (graph[node][i]) {
#             #pragma omp task
#             dfsTask(i, n);
#         }
#     }
# 
#     #pragma omp taskwait
# }
# 
# void parallelDFS(int start, int n) {
#     #pragma omp parallel
#     {
#         #pragma omp single
#         {
#             dfsTask(start, n);
#         }
#     }
# }
# 
# int main() {
#     int n = 6;
# 
#     int adjacencyMatrix[6][6] = {
#         {0, 1, 1, 0, 0, 0},
#         {1, 0, 0, 1, 1, 0},
#         {1, 0, 0, 0, 1, 0},
#         {0, 1, 0, 0, 0, 1},
#         {0, 1, 1, 0, 0, 1},
#         {0, 0, 0, 1, 1, 0}
#     };
# 
#     for (int i = 0; i < n; i++)
#         for (int j = 0; j < n; j++)
#             graph[i][j] = adjacencyMatrix[i][j];
# 
#     printf("Parallel BFS:\n");
#     for (int i = 0; i < n; i++) visited[i] = 0;
#     front = 0, rear = -1;
#     parallelBFS(0, n);
# 
#     printf("\nParallel DFS:\n");
#     for (int i = 0; i < n; i++) visited[i] = 0;
#     parallelDFS(0, n);
# 
#     return 0;
# }
#

!gcc -fopenmp parallel_bfs_dfs.c -o parallel_bfs_dfs

!./parallel_bfs_dfs







'''The provided code demonstrates parallel implementations of **Breadth-First Search (BFS)** and **Depth-First Search (DFS)** on an undirected graph using OpenMP (Open Multi-Processing), which is a parallel programming API for C/C++ and Fortran. OpenMP allows you to parallelize tasks by adding simple compiler directives. Here is a detailed explanation of the key components and concepts used in the code:

### Key Concepts:

1. **OpenMP**:

   * OpenMP is a programming model that allows developers to easily parallelize their code. It uses compiler directives to parallelize loops, functions, and tasks. It provides constructs like `#pragma` for specifying parallel regions, tasks, and synchronization mechanisms.
   * In this code, OpenMP is used to parallelize the BFS and DFS algorithms by allowing multiple threads to work concurrently.

2. **Graph Representation**:

   * The graph is represented as an **adjacency matrix**, where each cell `graph[i][j]` represents the edge between node `i` and node `j`. If there is an edge, the value is `1`; otherwise, it's `0`. This matrix is used in both BFS and DFS to explore neighboring nodes.

3. **Parallel BFS**:

   * **BFS** is a traversal algorithm where nodes are explored level by level. It uses a **queue** to manage the nodes to visit.
   * The `parallelBFS` function performs a parallelized BFS:

     * It starts from the given node and adds it to the queue.
     * Then, it processes the queue in parallel using the `#pragma omp parallel for` directive. This allows multiple threads to dequeue nodes and explore their neighbors simultaneously.
     * **Critical Sections**: The `#pragma omp critical` directives are used to ensure that the shared resources (the queue and the `visited` array) are accessed safely by multiple threads.

4. **Parallel DFS**:

   * **DFS** is a traversal algorithm where nodes are explored as deep as possible along each branch before backtracking. It uses **recursion** and can be easily parallelized by creating multiple tasks for each recursive call.
   * The `parallelDFS` function demonstrates how to parallelize DFS using OpenMP tasks:

     * The `dfsTask` function is defined as a task and is invoked using `#pragma omp task`.
     * The task processes the node, marking it as visited, and then spawns new tasks for unvisited neighbors.
     * **Task Synchronization**: The `#pragma omp taskwait` directive ensures that all tasks spawned by the current task are completed before the task finishes.

### Code Explanation:

#### Step 1: Graph Initialization

The graph is represented as a 6x6 adjacency matrix that defines the structure of the graph. Each node is connected to other nodes according to the matrix. The `visited` array tracks whether a node has been visited during traversal.

#### Step 2: BFS Implementation (`parallelBFS`)

* **Queue Management**: The `enqueue` and `dequeue` functions manage the queue. The queue is used to keep track of nodes that need to be visited.
* **Parallelization**: The BFS process is parallelized using OpenMP's `#pragma omp parallel for`. Multiple threads are spawned to process nodes in the queue simultaneously. However, the queue and visited array are shared resources, so care is taken to protect them using `#pragma omp critical` to prevent data races.
* **Traversal**: Each thread processes one node, marks it as visited, and enqueues its neighbors. This continues until the queue is empty.

#### Step 3: DFS Implementation (`parallelDFS`)

* **Task-based Parallelism**: DFS is parallelized using OpenMP's task constructs. Each recursive call to `dfsTask` is treated as a separate task, allowing threads to explore different branches of the graph concurrently.
* **Task Synchronization**: The `#pragma omp taskwait` directive ensures that all tasks are completed before the function returns, preventing premature termination of the DFS.
* **Critical Section**: Similar to BFS, a critical section is used to ensure that the `visited` array is accessed safely by multiple threads.

#### Step 4: Compilation and Execution

* The C code is compiled using `gcc -fopenmp` to enable OpenMP support.
* The resulting executable is run to perform parallel BFS and DFS on the graph.

### Parallelism in BFS and DFS:

* **BFS Parallelism**: The BFS algorithm processes nodes level by level, which allows for parallelism at each level. OpenMP parallelizes the exploration of neighboring nodes.
* **DFS Parallelism**: In DFS, each recursive call is a separate task. OpenMP spawns tasks for each unvisited neighbor, allowing for concurrent exploration of different branches of the graph.

### Benefits of Parallelization:

1. **Improved Performance**: By utilizing multiple threads, the BFS and DFS algorithms can process nodes in parallel, reducing the overall time needed for traversal, especially for large graphs.
2. **Scalability**: The code can be easily scaled by increasing the number of threads, enabling it to handle larger graphs more efficiently.
3. **Resource Utilization**: OpenMP automatically manages the distribution of tasks across available cores, making better use of the CPU.

### Conclusion:

This code demonstrates how parallel programming techniques like OpenMP can be applied to traditional graph traversal algorithms like BFS and DFS. By parallelizing the tasks and threads, the performance of these algorithms is improved, especially when working with large graphs. OpenMP simplifies the parallelization process and provides a powerful tool for enhancing the efficiency of algorithms.
'''

