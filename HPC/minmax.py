# -*- coding: utf-8 -*-
"""HPC3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/192pYW5_yUZCYKlYbRqVac34G-P3MUhYt
"""

!apt update -y
!apt install gcc -y

# Commented out IPython magic to ensure Python compatibility.
# %%writefile reduction_operations.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <omp.h>
# 
# #define SIZE 100000
# 
# int main() {
#     int arr[SIZE];
#     for (int i = 0; i < SIZE; i++) {
#         arr[i] = rand() % 100000;
#     }
# 
#     int minVal = arr[0];
#     int maxVal = arr[0];
#     long long sum = 0;
#     double average = 0.0;
# 
#     double start = omp_get_wtime();
# 
#     // Parallel Reduction
#     #pragma omp parallel for reduction(min:minVal) reduction(max:maxVal) reduction(+:sum)
#     for (int i = 0; i < SIZE; i++) {
#         if (arr[i] < minVal) minVal = arr[i];
#         if (arr[i] > maxVal) maxVal = arr[i];
#         sum += arr[i];
#     }
# 
#     average = (double)sum / SIZE;
# 
#     double end = omp_get_wtime();
# 
#     // Output results
#     printf("Minimum: %d\n", minVal);
#     printf("Maximum: %d\n", maxVal);
#     printf("Sum: %lld\n", sum);
#     printf("Average: %.2f\n", average);
#     printf("Time Taken: %f seconds\n", end - start);
# 
#     return 0;
# }
#

!gcc -fopenmp reduction_operations.c -o reduction_ops

!./reduction_ops


'''The provided code demonstrates the use of **parallel reduction operations** using OpenMP in C. The goal is to compute some basic statistical metrics—**minimum**, **maximum**, **sum**, and **average**—on a large array of random integers, leveraging parallelism to speed up the computation. Here's a detailed explanation of the key concepts and functionality of the code:

### Key Concepts:

1. **Parallel Reduction**:

   * Reduction is a process of combining results from multiple threads into a single result. In this code, we use parallel reduction to compute the **minimum**, **maximum**, and **sum** of the array elements concurrently.
   * OpenMP provides a way to perform reductions on variables using the `reduction` clause. This clause ensures that each thread computes a partial result and then these partial results are combined at the end to obtain the final result.

2. **OpenMP**:

   * OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran. It is used here to parallelize the `for` loop that iterates through the array to compute the statistical metrics.
   * The `#pragma omp parallel for` directive is used to parallelize the `for` loop. The `reduction` clause is applied to the variables `minVal`, `maxVal`, and `sum`, so that each thread computes partial values of these variables in parallel and then combines them after the loop completes.

3. **Reduction Operations**:

   * **Minimum**: The minimum value in the array is calculated by comparing each element with the current minimum.
   * **Maximum**: The maximum value is calculated by comparing each element with the current maximum.
   * **Sum**: The sum of all the elements is computed by adding each element to a running total.
   * **Average**: The average is calculated by dividing the total sum by the size of the array.

4. **Performance Optimization**:

   * By using parallel reduction, the program can perform these operations more efficiently on large arrays, utilizing multiple cores of the CPU for faster computation.
   * The `reduction(min:minVal)`, `reduction(max:maxVal)`, and `reduction(+:sum)` clauses ensure that the threads perform the reduction operation in parallel, and their partial results are combined in a thread-safe manner.

### Code Breakdown:

#### Step 1: Array Initialization

* An array of size `SIZE` (100,000 elements) is created. Each element of the array is initialized to a random integer between 0 and 99,999 using the `rand()` function.

#### Step 2: Initialization of Variables

* **minVal** and **maxVal** are initialized to the first element of the array (`arr[0]`), while **sum** and **average** are initialized to 0.
* **minVal** will hold the smallest value in the array, **maxVal** will hold the largest value, and **sum** will accumulate the total sum of the array elements.

#### Step 3: Parallel Reduction

* The `#pragma omp parallel for` directive is used to parallelize the loop that iterates over the array:

  * The `reduction(min:minVal)`, `reduction(max:maxVal)`, and `reduction(+:sum)` clauses tell the compiler to treat these variables as private for each thread. Each thread will calculate its own partial value, and at the end of the loop, the partial values will be combined (reduced) into the final result.
  * The loop performs the following operations for each element of the array:

    * **minVal**: The thread checks if the current element is smaller than the current minimum value and updates it accordingly.
    * **maxVal**: Similarly, the thread checks if the current element is larger than the current maximum value.
    * **sum**: The thread adds the current element to the sum.

#### Step 4: Average Calculation

* After the loop completes, the `sum` is divided by `SIZE` to compute the average of the array elements.

#### Step 5: Performance Measurement

* The program measures the time taken to perform the reduction operations using `omp_get_wtime()`, which returns the wall clock time (in seconds).
* The time taken for the parallel reduction is printed, along with the computed **minimum**, **maximum**, **sum**, and **average** values.

#### Step 6: Compilation and Execution

* The program is compiled with `gcc -fopenmp`, enabling OpenMP support for parallel execution.
* After compiling, the executable is run, and the statistical results (minimum, maximum, sum, average) and the time taken for the parallel reduction are displayed.

### Code Performance:

1. **Parallel Reduction**:

   * The main advantage of using parallel reduction in this code is that it allows the program to compute the statistical metrics much faster by utilizing multiple CPU cores.
   * Each thread processes a portion of the array, and after the loop completes, the partial results are combined using the `reduction` clause.
   * This leads to a significant speedup, especially when the array size is large (in this case, 100,000 elements).

2. **Efficiency**:

   * Without OpenMP parallelism, the program would perform these calculations sequentially, which would take significantly more time for large arrays.
   * Parallelizing the reduction allows the program to scale with the number of available CPU cores, making it much faster than the sequential version.

### Conclusion:

This code demonstrates how to efficiently compute the **minimum**, **maximum**, **sum**, and **average** of an array using **parallel reduction** with OpenMP. By using the `reduction` clause, the program ensures that each thread works on a subset of the data and combines their results safely at the end of the computation. This approach significantly reduces the execution time, especially when dealing with large datasets. OpenMP is a powerful tool for parallel programming, allowing developers to easily take advantage of multi-core processors to speed up their computations.
'''
