# -*- coding: utf-8 -*-
"""StockDL4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ep7rJ2ejQSCBMmCPG6YcpmN8qCnyxlgI
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import datetime
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from sklearn.metrics import r2_score

data = pd.read_csv('Google_Stock_Price_Train.csv',thousands=',')
data

ax1 = data.plot(x="Date", y=["Open", "High", "Low", "Close"], figsize=(10,7),title='Open, High, Low, Close Stock Prices of Google Stocks')
ax1.set_ylabel("Stock Price")

ax2 = data.plot(x="Date", y=["Volume"],  figsize=(10,7))
ax2.set_ylabel("Stock Volume")

data.isna().sum()

data[['Open','High','Low','Close','Volume']].plot(kind='box', layout=(1,5), subplots=True, sharex=False, sharey=False, figsize=(10,7),color='red')
plt.show()

data.hist(figsize=(10,7))
plt.show()

scaler = MinMaxScaler()
data_without_date = data.drop("Date", axis=1)
scaled_data = pd.DataFrame(scaler.fit_transform(data_without_date))

scaled_data.hist(figsize=(10,7))
plt.show()

plt.figure(figsize=(10,7))
sns.heatmap(data.drop("Date", axis=1).corr())
plt.show()

scaled_data = scaled_data.drop([0, 2, 3], axis=1)
scaled_data

def split_seq_multivariate(sequence, n_past, n_future):

    '''
    n_past ==> no of past observations
    n_future ==> no of future observations
    '''
    x = []
    y = []
    for window_start in range(len(sequence)):
        past_end = window_start + n_past
        future_end = past_end + n_future
        if future_end > len(sequence):
            break
        # slicing the past and future parts of the window (this indexing is for 2 features vala data only)
        past = sequence[window_start:past_end, :]
        future = sequence[past_end:future_end, -1]
        x.append(past)
        y.append(future)

    return np.array(x), np.array(y)

n_steps = 60

scaled_data = scaled_data.to_numpy()
scaled_data.shape

x, y = split_seq_multivariate(scaled_data, n_steps, 1)

x.shape, y.shape

y = y[:, 0]
y.shape

x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2, random_state=42)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

model = Sequential()
model.add(LSTM(612, input_shape=(n_steps, 2)))
model.add(Dense(50, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(30, activation='relu'))
model.add(Dense(1))

model.summary()

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = model.fit(x_train, y_train, epochs=50, batch_size=32, verbose=2, validation_data=(x_test, y_test))#increase epoch as needed to 250

pd.DataFrame(history.history).plot(figsize=(10,7))

model.evaluate(x_test, y_test)

predictions = model.predict(x_test)
predictions.shape

plt.plot(y_test, c = 'r')
plt.plot(predictions, c = 'y')
plt.xlabel('Day')
plt.ylabel('Stock Price Volume')
plt.title('Stock Price Volume Prediction Graph using RNN (LSTM)')
plt.legend(['Actual','Predicted'], loc = 'lower right')
plt.figure(figsize=(10,7))
plt.show()

"""

Time Series Prediction with RNNs (LSTMs) and Code Explanation
Predicting future stock prices from historical data is a time series problem. Traditional machine learning struggles with the inherent sequential nature of this data, where past values influence future ones.

Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) Networks:

RNNs are designed for sequential data, using a "memory" to consider past inputs. However, standard RNNs can struggle with long sequences due to vanishing/exploding gradients. LSTMs are a specialized RNN architecture that overcomes this using "gates" to control information flow within their memory cells, allowing them to learn long-term dependencies.

Applying LSTMs to Stock Prices (as demonstrated in your code):

Your Python code implements a stock price prediction system using an LSTM network. Here's a breakdown of its key steps:

Data Loading and Exploration: The code begins by loading the Google stock price dataset using pandas. It then visualizes the 'Open', 'High', 'Low', 'Close' prices and 'Volume' over time, checks for missing values, and explores the distribution and potential outliers in the data using box plots and histograms.

Data Preprocessing:

Numerical features (excluding 'Date') are scaled using MinMaxScaler to the range [0, 1]. This helps in faster and more stable training of the neural network.
The 'Open', 'High', and 'Low' columns are dropped, focusing the prediction on the 'Close' price and 'Volume'.
The split_seq_multivariate function transforms the sequential data into input-output pairs. It creates sequences of the past n_steps (here, 60) days of 'Close' price and 'Volume' as input (x), and the corresponding next day's 'Close' price as the target (y).
Data Splitting: The prepared data is split into training and testing sets using train_test_split. The model learns from the training data and its performance is evaluated on the unseen testing data.

Model Building: A sequential LSTM model is created using Keras/TensorFlow. It consists of:

An LSTM layer with 612 units, taking sequences of 60 time steps with 2 features as input.
Several Dense (fully connected) layers with ReLU activation to learn complex relationships.
A final Dense layer with a single output unit to predict the next day's stock volume.
Model Compilation and Training: The model is compiled with the Adam optimizer, Mean Squared Error (MSE) as the loss function, and Mean Absolute Error (MAE) as 1  a metric. It is then trained on the training data using model.fit() for a specified number of epochs. The training progress, including loss on the training and validation sets, is recorded.


Model Evaluation: The trained model is evaluated on the test data using model.evaluate() to assess its prediction accuracy.

Prediction and Visualization: The model makes predictions on the test data using model.predict(). The actual and predicted stock volumes are then plotted to visually compare the model's performance.

In essence, the code:

Loads and prepares historical Google stock data.
Creates sequences of past 'Close' price and 'Volume' to predict future 'Volume'.
Builds and trains an LSTM neural network to learn these relationships.
Evaluates the model's ability to predict future stock volume on unseen data.
Visualizes the model's predictions against the actual values.
This demonstrates a practical application of LSTMs for time series forecasting in the context of stock market analysis."""

